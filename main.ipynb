{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42667643",
   "metadata": {},
   "source": [
    "Setting up dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408dd683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved datasets, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Youtube Dataset: 100%|██████████| 79346/79346 [00:00<00:00, 445902.68it/s]\n",
      "Loading ActivityNet open questions Dataset: 100%|██████████| 2950/2950 [00:00<00:00, 454345.71it/s]\n",
      "Loading Next QO-A Dataset: 100%|██████████| 5492/5492 [00:00<00:00, 426489.37it/s]\n",
      "Loading Next Q-A Dataset: 100%|██████████| 5496/5496 [00:00<00:00, 96810.74it/s]\n",
      "Loading Perception Dataset:   0%|          | 0/1785 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from loader import *\n",
    "from frcnn_plus_vbertembedding import FRCNN_VisualBert_Embedding\n",
    "from videohandler import *\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model = FRCNN_VisualBert_Embedding()\n",
    "\n",
    "rawdataYoutube = LoadYoutubetDataset()\n",
    "rawdataActivityNet = LoadActivityNetDataset()\n",
    "rawdataQA = LoadNextQA_OE()\n",
    "rawdataQA2 = LoadNextQA_MC()\n",
    "rawdataperception = LoadPerceptionDataset()\n",
    "print(\"retrieved datasets, loading...\")\n",
    "training_data, labels_data, names, sources = LoadDatasets(rawdataYoutube, rawdataActivityNet, rawdataQA, rawdataQA2, rawdataperception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e8b2",
   "metadata": {},
   "source": [
    "Now we train the model!:: relgjeogjwohontrnbor\n",
    "# Add a buffer dataset with half the proccess done to do faster inference on my second device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size of 14218 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Backbone on the training dataset and storing the results:   0%|          | 0/14218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames from ytb_wrzuk820tYo.mp4\n",
      "remaning frames 9\n",
      "remaning frames 8\n",
      "remaning frames 7\n",
      "remaning frames 6\n",
      "remaning frames 5\n",
      "remaning frames 4\n",
      "remaning frames 3\n",
      "remaning frames 2\n",
      "remaning frames 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Backbone on the training dataset and storing the results:   0%|          | 1/14218 [01:37<385:36:31, 97.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaning frames 0\n",
      "Extracting frames from ytb_M0sSmNFpB9k.mp4\n",
      "remaning frames 9\n",
      "remaning frames 8\n",
      "remaning frames 7\n",
      "remaning frames 6\n",
      "remaning frames 5\n",
      "remaning frames 4\n",
      "remaning frames 3\n",
      "remaning frames 2\n",
      "remaning frames 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Backbone on the training dataset and storing the results:   0%|          | 2/14218 [03:21<399:39:27, 101.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaning frames 0\n",
      "Extracting frames from ytb_3BaZGu3xUDA.mp4\n",
      "remaning frames 12\n",
      "remaning frames 11\n",
      "remaning frames 10\n",
      "remaning frames 9\n",
      "remaning frames 8\n",
      "remaning frames 7\n",
      "remaning frames 6\n",
      "remaning frames 5\n",
      "remaning frames 4\n",
      "remaning frames 3\n",
      "remaning frames 2\n",
      "remaning frames 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Backbone on the training dataset and storing the results:   0%|          | 3/14218 [05:32<454:28:23, 115.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaning frames 0\n",
      "Extracting frames from ytb_0OHWU4bVIU0.mp4\n",
      "remaning frames 6\n",
      "remaning frames 5\n",
      "remaning frames 4\n",
      "remaning frames 3\n",
      "remaning frames 2\n",
      "remaning frames 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Backbone on the training dataset and storing the results:   0%|          | 4/14218 [06:38<377:23:40, 95.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaning frames 0\n",
      "Extracting frames from ytb_RxgGd4cNxJk.mp4\n",
      "remaning frames 8\n",
      "remaning frames 7\n",
      "remaning frames 6\n",
      "remaning frames 5\n",
      "remaning frames 4\n",
      "remaning frames 3\n",
      "remaning frames 2\n",
      "remaning frames 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Backbone on the training dataset and storing the results:   0%|          | 5/14218 [08:18<383:58:11, 97.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaning frames 0\n",
      "Extracting frames from ytb_S4V3oST1P-A.mp4\n",
      "remaning frames 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataset size of \"+str(len(training_data))+\" videos\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "   \n",
    "buffer_dataset = []\n",
    "current = 0\n",
    "try :\n",
    "   for i in tqdm(range(0, len(training_data)), desc=\"Running Backbone on the training dataset and storing the results\"):\n",
    "      current = i\n",
    "      try:\n",
    "\n",
    "         prompt = training_data[i][0]\n",
    "         video = training_data[i][1]\n",
    "         video_to_frames((video), \"temp\")\n",
    "         if sources[i] == \"youtube\":\n",
    "\n",
    "               for frame in os.listdir(\"temp/ytb_\"+names[i]+\".mp4\"):\n",
    "                  path = os.path.join(\"temp/ytb_\"+names[i]+\".mp4\", frame)\n",
    "                  Embedding = model.forward(path, prompt)\n",
    "                  buffer_dataset.append(Embedding)\n",
    "                  os.remove(path)\n",
    "        \n",
    "                  print(\"remaning frames \"+str(len(os.listdir(\"temp/ytb_\"+names[i]+\".mp4\"))))\n",
    "         elif sources[i] == \"activitynet\":\n",
    "        \n",
    "               for frame in os.listdir(\"temp/\"+names[i]+\".mp4\"):\n",
    "                  path = os.path.join(\"temp/\"+names[i]+\".mp4\", frame)\n",
    "                  Embedding = model.forward(path, prompt)\n",
    "                  buffer_dataset.append(Embedding)\n",
    "                  os.remove(path)\n",
    "           \n",
    "                  print(\"remaning frames \"+str(len(os.listdir(\"temp/\"+names[i]+\".mp4\"))))\n",
    "         elif sources[i] == \"NEXTQA\":\n",
    "         \n",
    "            for frame in os.listdir(\"temp/\"+names[i]+\".mp4\"):\n",
    "               path = os.path.join(\"temp/\"+names[i]+\".mp4\", frame)\n",
    "               Embedding = model.forward(path, prompt)\n",
    "               buffer_dataset.append(Embedding)\n",
    "               os.remove(path)\n",
    "           \n",
    "               print(\"remaning frames \"+str(len(os.listdir(\"temp/\"+names[i]+\".mp4\"))))\n",
    "        \n",
    "         elif sources[i] == \"perception\":\n",
    "        \n",
    "            for frame in os.listdir(\"temp/\"+names[i]+\".mp4\"):\n",
    "               path = os.path.join(\"temp/\"+names[i]+\".mp4\", frame)\n",
    "               Embedding = model.forward(path, prompt)\n",
    "               buffer_dataset.append(Embedding)\n",
    "               os.remove(path)\n",
    "          \n",
    "               print(\"remaning frames \"+str(len(os.listdir(\"temp/\"+names[i]+\".mp4\"))))\n",
    "      except Exception as e:\n",
    "         print(e)\n",
    "         continue\n",
    "except Exception as e:\n",
    "   print(e)\n",
    "   i, buffer_dataset = STARTFROMI(current+1, training_data, model, buffer_dataset, sources, names, video_to_frames)\n",
    "   current = i\n",
    "   try:\n",
    "      i, buffer_dataset = STARTFROMI(current+1, training_data, model, buffer_dataset, sources, names, video_to_frames)\n",
    "   except Exception as e:\n",
    "      print(e)\n",
    "      pass\n",
    "try:\n",
    "   torch.save(buffer_dataset, \"bufferdataset\")\n",
    "except Exception as e:\n",
    "   pass\n",
    "try:\n",
    "   torch.save(buffer_dataset, \"buffer_dataset.pt\")\n",
    "except Exception as e:\n",
    "   pass\n",
    "try:\n",
    "   \n",
    "   torch.save(buffer_dataset, \"bufferdataset.pth\")\n",
    "except Exception as e:\n",
    "   pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
